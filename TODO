try to understand limitation of model's vision

Later I will multithread learning, but not now.

16 to 12 no walls.

get rifd of going back

Implement normal path finding for reward to reward for moving in direction for food even if tailiis on the way (go around)

bootstrapping

Why gamma in belman euasion is 0.95?

can we write a mentor/trainer for model? Or it will be too hard?

have multiple starting positions with different length

difference between soft and hard update

write all in c++

how many layers will be enough? how many neurons?
