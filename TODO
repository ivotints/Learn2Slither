try to understand limitation of model's vision

Later I will multithread learning, but not now.

16 to 12 no walls.

get rifd of going back

Implement normal path finding for reward to reward for moving in direction for food even if tailiis on the way (go around)

bootstrapping

Why gamma in belman euasion is 0.95?

can we write a mentor/trainer for model? Or it will be too hard?

have multiple starting positions with different length

difference between soft and hard update

write all in c++

how many layers will be enough? how many neurons?

If it sees Green, reward for moving to it and punich for other

Snake goes inside of itself. Can we us A* parh finding to predict 5 moves ahead that some move is deadly and punish for moving there?